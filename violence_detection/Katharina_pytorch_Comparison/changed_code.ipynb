{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEY MODIFICATIONS\n",
    "\n",
    "1. Load the three specific images manually using a file path \n",
    "2. Prepocess the images using the \"prepocess\" function from CLIP \n",
    "3. Compute the embeddings for these images using the model\n",
    "4. Compute the similarity scores against the predefined text features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erkl√§rungen \n",
    "\n",
    "1. Specific Image Paths: The Image_paths list contains the file paths of the three JPEG images you wnar to test \n",
    "2. Image oading: Each image is loaded using PIL.IMAGe and converted to RGB to ensure compatability with CLIP \n",
    "3. Prpeocessing: Each image is preprocessed sing the preprocess function from CLIP to prepare it for the model \n",
    "4. Embedding and Similarity Calculation: The image embedding is calcualted, normlaized and compared against the text emebddings using the dot product \n",
    "5. Save Results: The similarity results are saved in a final_res/sim_violence_test.torch file for later use\n",
    "6. Error Handling: Added a try-except block to handle potential issues like missing files or unsupported image formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "Similarity Scores: The similarity scores for each image against the predefined text prompts are printed.\n",
    "Saved Results: The similarity results are saved to final_res/sim_violence_test.torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the 3 specific JPEG images\n",
    "#image_paths = [\"path/to/image1.jpg\", \"path/to/image2.jpg\", \"path/to/image3.jpg\"]\n",
    "#image_paths = \"/Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test\"\n",
    "# Specify the folder containing the images\n",
    "folder_path = \"/Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test\"\n",
    "\n",
    "# Collect all image file paths\n",
    "supported_formats = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")  # Add formats if needed\n",
    "image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith(supported_formats)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "    (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (12): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (13): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (14): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (15): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (16): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (17): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (18): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (19): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (20): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (21): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (22): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (23): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 768)\n",
       "  (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CLIP model\n",
    "model_name = \"ViT-L/14\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, preprocess = clip.load(model_name, device=device)\n",
    "print(\"Model loaded successfully!\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define safety-related text prompts\n",
    "text_prompts = [\n",
    "    \"a photo of a gun\", \"a photo of a shooting\", \"a photo of a weapon\",\n",
    "    \"a photo of a killing\", \"a photo of a bomb\", \"a photo of violence\",\n",
    "    \"a photo of other\", \"a photo of an animal\", \"a photo of a family\",\n",
    "    \"a photo of a meeting\", \"a photo of a tool\", \"a photo of a gathering\"\n",
    "]\n",
    "text_tokens = clip.tokenize(text_prompts).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute text embeddings\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_tokens).to(torch.float32)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and evaluate the images\n",
    "final_sim = {}\n",
    "for image_path in image_paths:\n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "        # Compute image embedding\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image_input).to(torch.float32)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # Compute similarity with text features\n",
    "        similarity = image_features @ text_features.T\n",
    "\n",
    "        # Store the results\n",
    "        final_sim[image_path] = similarity.cpu().numpy()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080638380466204672_2019-01-03.jpg: [[0.13073185 0.15786709 0.1665825  0.17108655 0.1298548  0.16919914\n",
      "  0.14559239 0.14970405 0.14161852 0.18379524 0.19505645 0.1744351 ]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080192181284028416_2019-01-01.jpg: [[0.10444829 0.13140208 0.12875149 0.14021097 0.11310031 0.13451204\n",
      "  0.15238331 0.12645964 0.12302336 0.1442782  0.14056309 0.15613508]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080618686275309569_2019-01-03.jpg: [[0.11240956 0.13696322 0.12213744 0.12752505 0.11690122 0.12085553\n",
      "  0.14820303 0.12832837 0.1251597  0.10867783 0.13771729 0.12637308]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080418713566887936_2019-01-02.jpg: [[0.06038975 0.11174168 0.09062684 0.11354461 0.10083479 0.09906158\n",
      "  0.09834988 0.09419607 0.12462182 0.1064276  0.07099092 0.14173062]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080544662945964033_2019-01-02.jpg: [[0.07964168 0.13655107 0.0979078  0.13614348 0.09508763 0.13541843\n",
      "  0.13944083 0.1312358  0.1388383  0.13370363 0.08620944 0.14753303]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080303178569207808_2019-01-02.jpg: [[0.05971264 0.07738364 0.09952001 0.07332951 0.0557878  0.09826221\n",
      "  0.10408454 0.05739847 0.07432234 0.1024859  0.08878504 0.11326605]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080234390649741312_2019-01-01.jpg: [[0.14577413 0.15036349 0.18041113 0.16461463 0.14674297 0.17273821\n",
      "  0.13498715 0.16405587 0.13770242 0.16265944 0.20464413 0.15009476]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080553849767845888_2019-01-02.jpg: [[0.1277802  0.13059309 0.15689504 0.14450958 0.12124541 0.146733\n",
      "  0.13804339 0.13271597 0.1367856  0.15239464 0.15753952 0.16315868]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1079931065068851203_2019-01-01.jpg: [[0.11328487 0.14309384 0.13388847 0.14362775 0.13102463 0.13185811\n",
      "  0.17223236 0.15210386 0.17148508 0.15556808 0.12354828 0.1720308 ]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080839774917836832_2019-01-03.jpg: [[0.04851238 0.09104469 0.09074153 0.09972719 0.08734195 0.10699092\n",
      "  0.12474889 0.06942098 0.08823561 0.12560557 0.09814507 0.13113844]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080192687377018880_2019-01-01.jpg: [[0.06403673 0.11350581 0.10074315 0.12157572 0.07746828 0.11381314\n",
      "  0.14519367 0.09668952 0.11694367 0.14435902 0.11863719 0.14656815]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080332859456610304_2019-01-02.jpg: [[0.14551842 0.16095304 0.1609982  0.16558477 0.14735681 0.16525474\n",
      "  0.14146982 0.15680069 0.13777128 0.16686289 0.19307911 0.17767084]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080494057963618305_2019-01-02.jpg: [[0.08869997 0.12724988 0.11543953 0.1331318  0.08232491 0.1102283\n",
      "  0.14858547 0.10554183 0.12779407 0.14496543 0.11246204 0.13114072]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080660544250470400_2019-01-03.jpg: [[0.15038285 0.15995246 0.16464752 0.15843162 0.15298031 0.14098099\n",
      "  0.16225451 0.14708509 0.15430309 0.14326034 0.1925737  0.15705445]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1081018933786816512_2019-01-04.jpg: [[0.12774545 0.135787   0.1436981  0.16053149 0.11174322 0.14660767\n",
      "  0.15163396 0.13718326 0.12158792 0.13938482 0.16143426 0.13531205]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080880672674320385_2019-01-03.jpg: [[0.11818691 0.12979434 0.13128828 0.14791504 0.11872217 0.14092147\n",
      "  0.14689837 0.18386522 0.15019673 0.13804922 0.14202473 0.15458967]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080476070879596545_2019-01-02.jpg: [[0.07250458 0.12379187 0.09301864 0.12980488 0.08584546 0.09834152\n",
      "  0.12691613 0.12016387 0.13110264 0.12738138 0.11693229 0.15113191]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080187938120454144_2019-01-01.jpg: [[0.13389722 0.15764287 0.15819308 0.14809522 0.165909   0.14074105\n",
      "  0.16780086 0.13295224 0.1286508  0.1609347  0.16302276 0.16114569]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080970837732347905_2019-01-03.jpg: [[0.16076106 0.1790882  0.16523048 0.18664908 0.13755007 0.1744332\n",
      "  0.15984088 0.15715307 0.15522467 0.16284664 0.15662375 0.16316596]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080685093167853569_2019-01-03.jpg: [[0.11589016 0.1421277  0.13001055 0.14385977 0.11327668 0.16492632\n",
      "  0.15767358 0.11836913 0.13008103 0.1432875  0.14561538 0.15030535]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080516853900861440_2019-01-02.jpg: [[0.09187817 0.14535613 0.10528229 0.14249785 0.10440132 0.11702777\n",
      "  0.13864571 0.12672386 0.13358931 0.14585505 0.1248005  0.15780064]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080884467231834112_2019-01-03.jpg: [[0.12950112 0.152313   0.14732985 0.154329   0.1284167  0.14806661\n",
      "  0.14759034 0.14002237 0.14059836 0.14932984 0.14774978 0.16340886]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080879718566715392_2019-01-03.jpg: [[0.07736662 0.08218316 0.11161266 0.11181915 0.0634659  0.11194132\n",
      "  0.11265278 0.08822138 0.11408094 0.11041895 0.09540818 0.11710331]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080523837207465985_2019-01-02.jpg: [[0.09419423 0.13619432 0.11543322 0.12479814 0.09955506 0.12638888\n",
      "  0.14271744 0.13274223 0.12390834 0.14247537 0.13379864 0.13540678]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080504503407915009_2019-01-02.jpg: [[0.14723887 0.17709783 0.13861209 0.14760298 0.14166117 0.14477912\n",
      "  0.16309676 0.12826025 0.14215015 0.1668203  0.13259928 0.1629147 ]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080216369348538368_2019-01-01.jpg: [[0.13389722 0.15764287 0.15819308 0.14809522 0.165909   0.14074105\n",
      "  0.16780086 0.13295224 0.1286508  0.1609347  0.16302276 0.16114569]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080388270813528064_2019-01-02.jpg: [[0.05360828 0.12234627 0.0987962  0.11862069 0.07224931 0.09257304\n",
      "  0.12790124 0.0649415  0.08174185 0.11238416 0.11998144 0.09225344]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1081133255385063425_2019-01-04.jpg: [[0.14470758 0.18469036 0.15528059 0.18830712 0.11671548 0.16939527\n",
      "  0.14781673 0.14160371 0.12786284 0.17067276 0.13824666 0.14483498]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080585447011766272_2019-01-02.jpg: [[0.1473192  0.15012375 0.17162146 0.15498781 0.12857956 0.14041726\n",
      "  0.13552916 0.15317117 0.12081023 0.15207711 0.19136456 0.1236238 ]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080542249518272518_2019-01-02.jpg: [[0.10440207 0.13987522 0.11445011 0.13604297 0.09633371 0.11518015\n",
      "  0.12865354 0.11557364 0.09470975 0.11463594 0.12495747 0.13717322]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080760016779558912_2019-01-03.jpg: [[0.10787213 0.13892293 0.12537134 0.15699144 0.10714818 0.12467284\n",
      "  0.14514163 0.12586002 0.11677635 0.14485505 0.12315237 0.13994521]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080305525563117570_2019-01-02.jpg: [[0.11601602 0.13516496 0.15773174 0.14827132 0.09452795 0.1359309\n",
      "  0.14805698 0.12252427 0.13455254 0.15820542 0.172584   0.15833452]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080749558655864832_2019-01-03.jpg: [[0.1574806  0.14438426 0.18104097 0.14442644 0.14906406 0.15651226\n",
      "  0.14691223 0.12020236 0.09873174 0.15265349 0.1540688  0.14610997]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080822854994874368_2019-01-03.jpg: [[0.07951662 0.1396566  0.10530645 0.12927637 0.07444488 0.12787952\n",
      "  0.12761945 0.09749915 0.1130021  0.15699624 0.12344077 0.15299642]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080724379325984768_2019-01-03.jpg: [[0.11240956 0.13696322 0.12213744 0.12752505 0.11690122 0.12085553\n",
      "  0.14820303 0.12832837 0.1251597  0.10867783 0.13771729 0.12637308]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1081051358705451008_2019-01-04.jpg: [[0.12707809 0.13828188 0.16035874 0.15593289 0.11579548 0.15531377\n",
      "  0.14131495 0.11807696 0.12778981 0.14970088 0.15226115 0.1376888 ]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1081129060590329857_2019-01-04.jpg: [[0.14952877 0.16031042 0.16012318 0.15595852 0.15154454 0.13692439\n",
      "  0.15490551 0.13577563 0.12717271 0.16946724 0.15443313 0.15321466]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080389038572478465_2019-01-02.jpg: [[0.11035573 0.13295445 0.13456391 0.11786896 0.11385769 0.11921215\n",
      "  0.14276306 0.10918425 0.12244092 0.14916162 0.139559   0.12613724]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080096060314447873_2019-01-01.jpg: [[0.13070096 0.15291671 0.14996548 0.16333477 0.15480639 0.1491257\n",
      "  0.18669927 0.16701674 0.18707065 0.1746022  0.13991381 0.18846866]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080686610826571776_2019-01-03.jpg: [[0.11240956 0.13696322 0.12213744 0.12752505 0.11690122 0.12085553\n",
      "  0.14820303 0.12832837 0.1251597  0.10867783 0.13771729 0.12637308]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080807685031936000_2019-01-03.jpg: [[0.11240956 0.13696322 0.12213744 0.12752505 0.11690122 0.12085553\n",
      "  0.14820303 0.12832837 0.1251597  0.10867783 0.13771729 0.12637308]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080466144497160193_2019-01-02.jpg: [[0.08048414 0.11845604 0.11333551 0.12308781 0.10021934 0.12458938\n",
      "  0.13991906 0.08965306 0.10492852 0.12260252 0.11182451 0.13041063]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080721929953251328_2019-01-03.jpg: [[0.14346206 0.15591228 0.15909976 0.15365624 0.14702249 0.13555276\n",
      "  0.15502104 0.14115079 0.14935486 0.14017108 0.18517525 0.15202822]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080626850483843072_2019-01-03.jpg: [[0.15038285 0.15995246 0.16464752 0.15843162 0.15298031 0.14098099\n",
      "  0.16225451 0.14708509 0.15430309 0.14326034 0.1925737  0.15705445]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080574283745701888_2019-01-02.jpg: [[0.15447603 0.16567487 0.15912378 0.17074698 0.14604226 0.17665944\n",
      "  0.16088335 0.175022   0.11218499 0.17813879 0.17863557 0.16429113]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080781129425317888_2019-01-03.jpg: [[0.11769762 0.15754704 0.16616419 0.18294924 0.1783102  0.15834904\n",
      "  0.14010479 0.11720656 0.11721255 0.16184156 0.16509989 0.16102993]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080388193130856449_2019-01-02.jpg: [[0.1162108  0.17739064 0.13229215 0.18201692 0.12815131 0.17293604\n",
      "  0.15094101 0.13385925 0.13904098 0.15288296 0.12586614 0.15126146]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080900401954803713_2019-01-03.jpg: [[0.10661601 0.12033035 0.12387127 0.10953439 0.11948206 0.14297356\n",
      "  0.13378137 0.10912657 0.12217585 0.1132981  0.12067095 0.11030993]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080811027321839616_2019-01-03.jpg: [[0.07457097 0.13453768 0.11943959 0.12164215 0.11002369 0.10512718\n",
      "  0.12372833 0.09143709 0.11045857 0.13277732 0.12303927 0.12699294]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1081146394398863363_2019-01-04.jpg: [[0.14930415 0.19644803 0.16810806 0.19694863 0.18225554 0.17470843\n",
      "  0.19462988 0.16519824 0.16704054 0.18846577 0.16054267 0.1918452 ]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080443642580488193_2019-01-02.jpg: [[0.12488531 0.10824651 0.14608046 0.11968967 0.0929715  0.13593918\n",
      "  0.11971324 0.09480607 0.08026014 0.0986824  0.15064499 0.11012669]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080101626344599553_2019-01-01.jpg: [[0.0740162  0.12949398 0.11624296 0.1351783  0.09752637 0.12871774\n",
      "  0.13049477 0.10729065 0.11584356 0.12807599 0.11013373 0.12532565]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080133838163099649_2019-01-01.jpg: [[0.08914976 0.10641124 0.10662662 0.10251631 0.08337048 0.09469755\n",
      "  0.12280998 0.09208244 0.1136415  0.11253437 0.10620997 0.1357333 ]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080211431864389633_2019-01-01.jpg: [[0.07987532 0.12425736 0.11588313 0.0844155  0.08307858 0.11484008\n",
      "  0.11538686 0.06724527 0.08490196 0.10132049 0.08457876 0.13919571]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080833692732403712_2019-01-03.jpg: [[0.14759345 0.16591462 0.16992535 0.18381086 0.12230593 0.17335272\n",
      "  0.17461811 0.16931666 0.1713192  0.18218634 0.18796863 0.18756773]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080935086021857280_2019-01-03.jpg: [[0.10479239 0.12384336 0.14433433 0.13988966 0.08088933 0.1259533\n",
      "  0.14020126 0.12004195 0.13296078 0.15039654 0.16325973 0.15445434]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080479052186746881_2019-01-02.jpg: [[0.11480281 0.11729907 0.1387671  0.13268012 0.09090041 0.14162618\n",
      "  0.15048002 0.11869795 0.10330036 0.12745824 0.14391385 0.13732913]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080506766855671809_2019-01-02.jpg: [[0.1048013  0.14700553 0.1149041  0.12634185 0.11136354 0.12000939\n",
      "  0.1544162  0.13423298 0.11902434 0.14534134 0.11047428 0.15956196]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1081115135559823360_2019-01-04.jpg: [[0.11886887 0.13469167 0.12124503 0.14287524 0.09857586 0.13106884\n",
      "  0.15949075 0.15890136 0.14424747 0.15564138 0.1394187  0.150307  ]]\n",
      "Similarity scores for /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1081116783849938945_2019-01-04.jpg: [[0.13613532 0.13430235 0.14210752 0.14092976 0.11454692 0.13625158\n",
      "  0.14490083 0.14166492 0.14011721 0.14200528 0.14863174 0.15721679]]\n"
     ]
    }
   ],
   "source": [
    "# Save the results\n",
    "torch.save(final_sim, \"sim_violence_test.torch\")\n",
    "\n",
    "# Print results\n",
    "for image_path, sim in final_sim.items():\n",
    "    print(f\"Similarity scores for {image_path}: {sim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example \n",
    "\n",
    "* jepg :id_1080638380466204672_2019-01-03.jpg\n",
    "\n",
    "[[0.13073185 0.15786709 0.1665825  0.17108655 0.1298548  0.16919914\n",
    "  0.14559239 0.14970405 0.14161852 0.18379524 0.19505645 0.1744351 ]]\n",
    "* jeder scroe stellt die √Ñhnlichkiet zwsichen einem Bild und einem der Text prompts da \n",
    "* => je j√∂her der Wert, desto n√§her ist das bild an der semnatsichen bedeutung \n",
    "\n",
    "* Example: \n",
    "    0,19505645 (h√∂chste Punktzahl in diesem Bereich) entspricht ‚Äûein Foto eines Werkzeugs‚Äú, was darauf hindeutet, dass diese Textaufforderung am besten mit den Merkmalen des Bildes √ºbereinstimmt\n",
    "    ...\n",
    "* Dieses Bild zeigt wahrscheinlich ein Werkzeug oder eine Szene, in der es um ein Treffen geht, da diese Kategorien die h√∂chste Punktzahl haben.\n",
    "Es ist weniger wahrscheinlich, dass es sich um gewaltbezogene Aufforderungen wie ‚Äûein Foto einer Waffe‚Äú oder ‚Äûein Foto einer Bombe‚Äú handelt, da diese niedrigere Punktzahlen haben."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiwi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
