{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract Relevant Data \n",
    "\n",
    "* From the JSON file, image-name needs to be extarcted and asssocicated classes \n",
    "* From the PyTorch similarity results, extract the image names and their highest similarity score along with the associated text prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Mapping \n",
    "\n",
    "* Map the image_name from both datasets\n",
    "* Pair the classes (from teh JSON) with the most rleveant text prompt and ist similarity score (from PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compare Results \n",
    "\n",
    "* For each image_name, check if the classes from the JSON file align with the highest similarity text prompt from PyTorch\n",
    "* Record matches and mismatches for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_prompts = [\n",
    "    \"a photo of a gun\", \"a photo of a shooting\", \"a photo of a weapon\",\n",
    "    \"a photo of a killing\", \"a photo of a bomb\", \"a photo of violence\",\n",
    "    \n",
    "    # Focus auf waffen \n",
    "    \"a photo of other\", \"a photo of an animal\", \"a photo of a family\",\n",
    "    \"a photo of a meeting\", \"a photo of a tool\", \"a photo of a gathering\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vk/m4mvvjw97z740q4bfjr898nm0000gn/T/ipykernel_8325/3237423483.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Get the highest similarity score and corresponding text prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmax_score_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_score_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mrelated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_prompts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_score_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "# Step 1: Load JSON and PyTorch results\n",
    "# Replace with your file paths\n",
    "json_file_path = \"weapon_classification_results.json\"\n",
    "torch_file_path = \"sim_violence_test.torch\"\n",
    "\n",
    "# Load JSON results\n",
    "with open(json_file_path, \"r\") as f:\n",
    "    weapon_results = json.load(f)\n",
    "\n",
    "# Load PyTorch similarity results\n",
    "torch_results = torch.load(torch_file_path, map_location=\"cpu\")\n",
    "\n",
    "# Step 2: Prepare a mapping from JSON\n",
    "json_mapping = {\n",
    "    entry[\"image_name\"]: entry[\"classes\"]\n",
    "    for entry in weapon_results[\"results\"]\n",
    "}\n",
    "\n",
    "# Step 3: Compare with PyTorch results\n",
    "comparison_results = []\n",
    "\n",
    "for image_path, similarity_scores in torch_results.items():\n",
    "    # Extract image name from the path (assuming it's the filename)\n",
    "    image_name = image_path.split(\"/\")[-1]\n",
    "    \n",
    "    # Get the highest similarity score and corresponding text prompt\n",
    "    max_score_idx = similarity_scores.argmax()\n",
    "    max_score = similarity_scores[max_score_idx]\n",
    "    related_text = text_prompts[max_score_idx]\n",
    "\n",
    "    # Check if the image is in the JSON results\n",
    "    if image_name in json_mapping:\n",
    "        detected_classes = json_mapping[image_name]\n",
    "        comparison_results.append({\n",
    "            \"image_name\": image_name,\n",
    "            \"detected_classes\": detected_classes,\n",
    "            \"torch_related_text\": related_text,\n",
    "            \"torch_similarity_score\": max_score,\n",
    "            \"match\": any(cls.lower() in related_text.lower() for cls in detected_classes)\n",
    "        })\n",
    "    else:\n",
    "        comparison_results.append({\n",
    "            \"image_name\": image_name,\n",
    "            \"detected_classes\": None,\n",
    "            \"torch_related_text\": related_text,\n",
    "            \"torch_similarity_score\": max_score,\n",
    "            \"match\": False\n",
    "        })\n",
    "\n",
    "# Step 4: Output Results\n",
    "for result in comparison_results:\n",
    "    print(f\"Image: {result['image_name']}\")\n",
    "    print(f\"  Detected Classes (JSON): {result['detected_classes']}\")\n",
    "    print(f\"  Torch Related Text: {result['torch_related_text']} (Score: {result['torch_similarity_score']:.3f})\")\n",
    "    print(f\"  Match: {'Yes' if result['match'] else 'No'}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Top Ten images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Images with Highest Similarity Scores:\n",
      "1. Image: /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080234390649741312_2019-01-01.jpg, Max Similarity Score: 0.205\n",
      "2. Image: /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1081146394398863363_2019-01-04.jpg, Max Similarity Score: 0.197\n",
      "3. Image: /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080638380466204672_2019-01-03.jpg, Max Similarity Score: 0.195\n",
      "4. Image: /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080332859456610304_2019-01-02.jpg, Max Similarity Score: 0.193\n",
      "5. Image: /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080660544250470400_2019-01-03.jpg, Max Similarity Score: 0.193\n",
      "6. Image: /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080626850483843072_2019-01-03.jpg, Max Similarity Score: 0.193\n",
      "7. Image: /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080585447011766272_2019-01-02.jpg, Max Similarity Score: 0.191\n",
      "8. Image: /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080096060314447873_2019-01-01.jpg, Max Similarity Score: 0.188\n",
      "9. Image: /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1081133255385063425_2019-01-04.jpg, Max Similarity Score: 0.188\n",
      "10. Image: /Users/apple/Documents/HIWI_Katharina/Hiwi_Katarina/violence_detection/Katharina_pytorch_Comparison/images_test/id_1080833692732403712_2019-01-03.jpg, Max Similarity Score: 0.188\n"
     ]
    }
   ],
   "source": [
    "# Extract top 10 images with highest similarity scores\n",
    "top_images = []\n",
    "\n",
    "for image_path, similarity_scores in torch_results.items():\n",
    "    # Get the highest similarity score for this image\n",
    "    max_score = similarity_scores.max()\n",
    "    top_images.append((image_path, max_score))\n",
    "\n",
    "# Sort by similarity score in descending order\n",
    "top_images = sorted(top_images, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the top 10 images\n",
    "top_10_images = top_images[:10]\n",
    "\n",
    "# Display the results\n",
    "print(\"Top 10 Images with Highest Similarity Scores:\")\n",
    "for rank, (image_path, score) in enumerate(top_10_images, start=1):\n",
    "    print(f\"{rank}. Image: {image_path}, Max Similarity Score: {score:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "# werte im range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vk/m4mvvjw97z740q4bfjr898nm0000gn/T/ipykernel_8325/4056378526.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity_scores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_score_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_score_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mrelated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_prompts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_score_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtop_images_with_prompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# Extract top 10 images with highest similarity scores and their related prompts\n",
    "top_images_with_prompts = []\n",
    "\n",
    "for image_path, similarity_scores in torch_results.items():\n",
    "    max_score_idx = similarity_scores.argmax()\n",
    "    max_score = similarity_scores[max_score_idx]\n",
    "    related_text = text_prompts[max_score_idx]\n",
    "    top_images_with_prompts.append((image_path, max_score, related_text))\n",
    "\n",
    "# Sort by similarity score in descending order\n",
    "top_images_with_prompts = sorted(top_images_with_prompts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the top 10 images\n",
    "top_10_images_with_prompts = top_images_with_prompts[:10]\n",
    "\n",
    "# Display the results\n",
    "print(\"Top 10 Images with Highest Similarity Scores and Related Prompts:\")\n",
    "for rank, (image_path, score, prompt) in enumerate(top_10_images_with_prompts, start=1):\n",
    "    print(f\"{rank}. Image: {image_path}, Max Similarity Score: {score:.3f}, Related Prompt: {prompt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a photo of a grenade' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vk/m4mvvjw97z740q4bfjr898nm0000gn/T/ipykernel_8325/1521426723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m category_indices = {\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"gun\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext_prompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a photo of a gun\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m\"grenade\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext_prompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a photo of a grenade\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Add if this was in your prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"knife\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext_prompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a photo of a knife\"\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# Add if this was in your prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m }\n",
      "\u001b[0;31mValueError\u001b[0m: 'a photo of a grenade' is not in list"
     ]
    }
   ],
   "source": [
    "# Define category indices based on text prompts\n",
    "category_indices = {\n",
    "    \"gun\": text_prompts.index(\"a photo of a gun\"),\n",
    "    \"grenade\": text_prompts.index(\"a photo of a grenade\"),  # Add if this was in your prompts\n",
    "    \"knife\": text_prompts.index(\"a photo of a knife\")      # Add if this was in your prompts\n",
    "}\n",
    "\n",
    "# Function to get top 10 images for a specific category\n",
    "def get_top_images_by_category(category, index, torch_results):\n",
    "    category_scores = []\n",
    "\n",
    "    for image_path, similarity_scores in torch_results.items():\n",
    "        # Extract the score for the specified category\n",
    "        score = similarity_scores[index]\n",
    "        category_scores.append((image_path, score))\n",
    "    \n",
    "    # Sort by similarity score in descending order\n",
    "    category_scores = sorted(category_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top 10 images\n",
    "    return category_scores[:10]\n",
    "\n",
    "# Get top 10 images for each category\n",
    "top_10_guns = get_top_images_by_category(\"gun\", category_indices[\"gun\"], torch_results)\n",
    "top_10_grenades = get_top_images_by_category(\"grenade\", category_indices[\"grenade\"], torch_results)\n",
    "top_10_knives = get_top_images_by_category(\"knife\", category_indices[\"knife\"], torch_results)\n",
    "\n",
    "# Display results\n",
    "print(\"Top 10 Images for Guns:\")\n",
    "for rank, (image_path, score) in enumerate(top_10_guns, start=1):\n",
    "    print(f\"{rank}. Image: {image_path}, Similarity Score: {score:.3f}\")\n",
    "\n",
    "print(\"\\nTop 10 Images for Grenades:\")\n",
    "for rank, (image_path, score) in enumerate(top_10_grenades, start=1):\n",
    "    print(f\"{rank}. Image: {image_path}, Similarity Score: {score:.3f}\")\n",
    "\n",
    "print(\"\\nTop 10 Images for Knives:\")\n",
    "for rank, (image_path, score) in enumerate(top_10_knives, start=1):\n",
    "    print(f\"{rank}. Image: {image_path}, Similarity Score: {score:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiwi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
